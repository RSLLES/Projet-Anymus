{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer, Input, Dense, Reshape, Flatten, Dropout, Concatenate, Add, Multiply\n",
    "from keras.layers import Activation\n",
    "import keras.backend as K\n",
    "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization as InstanceNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 3\n",
    "dim = 128\n",
    "input_shape = (dim,dim,channel)\n",
    "n_resnet = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(layer_input, filters, f_size=4, strides=2, normalization=True):\n",
    "    \"\"\"Layer de base pour downsamplé\"\"\"\n",
    "    l = Conv2D(filters, kernel_size=f_size, strides=strides, padding='same')(layer_input)\n",
    "    if normalization:\n",
    "        l = InstanceNormalization()(l)\n",
    "    l = LeakyReLU(alpha=0.2)(l)\n",
    "    return l\n",
    "\n",
    "def deconv2d(layer_input, filters, f_size=4):\n",
    "    \"\"\"Layers used during upsampling\"\"\"\n",
    "    u = UpSampling2D(size=2)(layer_input)\n",
    "    u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "    u = AdaLIN_simple()(u)\n",
    "    return u\n",
    "\n",
    "def resnet(layer_input, filters, f_size=3):\n",
    "    l = Conv2D(filters, kernel_size=f_size, strides=1, padding='same')(layer_input)\n",
    "    l = InstanceNormalization()(l)\n",
    "    l = LeakyReLU(alpha=0.2)(l)\n",
    "    l = Conv2D(filters, kernel_size=f_size, strides=1, padding='same')(l)\n",
    "    l = InstanceNormalization()(l)\n",
    "    return Add()([l, layer_input])\n",
    "\n",
    "def resnet_adalin(layer_input, gamma, beta, f_size=3):\n",
    "    filters = layer_input.shape[-1]\n",
    "    l = Conv2D(filters, kernel_size=f_size, strides=1, padding='same')(layer_input)\n",
    "    l = AdaLIN()([l, gamma, beta])\n",
    "    l = LeakyReLU(alpha=0.2)(l)\n",
    "    l = Conv2D(filters, kernel_size=f_size, strides=1, padding='same')(l)\n",
    "    l = AdaLIN()([l, gamma, beta])\n",
    "    return Add()([l, layer_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=input_shape)\n",
    "input_layer.shape\n",
    "depth = channel\n",
    "g = conv2d(input_layer, depth, f_size=7, strides=1)\n",
    "for _ in range(2):\n",
    "    depth*=2\n",
    "    g = conv2d(g, depth, f_size=3, strides=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'leaky_re_lu_39/LeakyRelu:0' shape=(None, 32, 32, 12) dtype=float32>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaLIN(Layer):\n",
    "    def __init__(self, smoothing=True, eps = 1e-5):\n",
    "        super(AdaLIN, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.eps = eps\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if (len(input_shape) != 3):\n",
    "            raise ValueError(\"Il faut donner dans l'ordre le layer, gamma et beta\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, gamma, beta = inputs[0], inputs[1], inputs[2]\n",
    "        ch = x.shape[-1]\n",
    "        ins_mean, ins_sigma = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        x_ins = (x - ins_mean) / (tf.sqrt(ins_sigma + self.eps))\n",
    "        ln_mean, ln_sigma = tf.nn.moments(x, axes=[1, 2, 3], keepdims=True)\n",
    "        x_ln = (x - ln_mean) / (tf.sqrt(ln_sigma + self.eps))\n",
    "        rho = tf.Variable(np.ones(ch), dtype = np.float32, name=\"rho\", shape=[ch], constraint=lambda x: tf.clip_by_value(x, clip_value_min=0.0, clip_value_max=1.0))\n",
    "        if self.smoothing :\n",
    "            rho = tf.clip_by_value(rho - tf.constant(0.1), 0.0, 1.0)\n",
    "        x_hat = rho * x_ins + (1 - rho) * x_ln\n",
    "        x_hat = x_hat * gamma + beta\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaLIN_simple(Layer):\n",
    "    def __init__(self, smoothing=True, eps = 1e-5):\n",
    "        super(AdaLIN_simple, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.eps = eps\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.ch = input_shape[-1]\n",
    "        self.gamma = tf.Variable(np.ones(self.ch), dtype = np.float32, name=\"gamma\", shape=[self.ch])\n",
    "        self.beta = tf.Variable(np.zeros(self.ch), dtype = np.float32, name=\"gamma\", shape=[self.ch])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        ins_mean, ins_sigma = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        x_ins = (x - ins_mean) / (tf.sqrt(ins_sigma + self.eps))\n",
    "        ln_mean, ln_sigma = tf.nn.moments(x, axes=[1, 2, 3], keepdims=True)\n",
    "        x_ln = (x - ln_mean) / (tf.sqrt(ln_sigma + self.eps))\n",
    "        rho = tf.Variable(np.zeros(self.ch), dtype = np.float32, name=\"rho\", shape=[self.ch], constraint=lambda x: tf.clip_by_value(x, clip_value_min=0.0, clip_value_max=1.0))\n",
    "        if self.smoothing :\n",
    "            rho = tf.clip_by_value(rho - tf.constant(0.1), 0.0, 1.0)\n",
    "        x_hat = rho * x_ins + (1 - rho) * x_ln\n",
    "        x_hat = x_hat * self.gamma + self.beta\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MUL(Layer):\n",
    "    def __init__(self):\n",
    "        super(MUL, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        if (len(input_shape) !=3):\n",
    "            raise ValueError(\"Il faut trois layer : le layer a mutlpplié, un layer dense de taille (batch,1) ainsi que son biais\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, w, b = inputs[0], inputs[1], inputs[2]\n",
    "        w = tf.gather(tf.transpose(tf.nn.bias_add(w, b)), 0)\n",
    "        return tf.multiply(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul(X):\n",
    "    x,w,b = X[0], X[1], X[2]\n",
    "    w = tf.gather(tf.transpose(tf.nn.bias_add(w, b)), 0)\n",
    "    return tf.multiply(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self):\n",
    "        super(Linear, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if (len(input_shape) != 2):\n",
    "            raise ValueError(\"Input shape : {}\".format(input_shape))\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[0][-1], 1),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(1,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "        super(Linear, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        r1 = tf.matmul(inputs[0], self.w) + self.b\n",
    "        w = tf.gather(tf.transpose(tf.nn.bias_add(self.w, self.b)), 0)\n",
    "        r2 = tf.multiply(inputs[1],w)\n",
    "        return [r1,r2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x25cbb229e08>"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_entree = Input(shape=(32,32,12))\n",
    "test_pool = GlobalAveragePooling2D()(test_entree)\n",
    "test_fin_pool, test_fin_normal = Linear()([test_pool, test_entree])\n",
    "Model(test_entree, test_fin_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'linear_60/Mul:0' shape=(None, 32, 32, 12) dtype=float32>"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fin_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'linear_42/add:0' shape=(None, 1) dtype=float32>"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x25cba49e748>"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class activation map\n",
    "gmv, gav = GlobalMaxPooling2D()(g), GlobalAveragePooling2D()(g)\n",
    "dense_m, dense_a = Dense(1), Dense(1)\n",
    "cam_m, cam_a = dense_m(gmv), dense_a(gav)\n",
    "\n",
    "g_m, g_a = Lambda(mul)([g, dense_m.weights[0], dense_m.weights[1]]), Lambda(mul)([g, dense_a.weights[0], dense_a.weights[1]])\n",
    "cam, g = Concatenate()([cam_m, cam_a]), Concatenate()([g_m, g_a])\n",
    "g = conv2d(g, depth, f_size=1, strides=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'leaky_re_lu_40/LeakyRelu:0' shape=(None, 32, 32, 12) dtype=float32>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_43/kernel:0' shape=(12, 1) dtype=float32, numpy=\n",
       "array([[ 0.35803616],\n",
       "       [-0.13402516],\n",
       "       [ 0.47078097],\n",
       "       [-0.5012767 ],\n",
       "       [ 0.41451585],\n",
       "       [ 0.18452203],\n",
       "       [-0.5768551 ],\n",
       "       [-0.6032223 ],\n",
       "       [-0.38289896],\n",
       "       [-0.6784733 ],\n",
       "       [-0.34806266],\n",
       "       [-0.2619669 ]], dtype=float32)>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes pour la ARLIN function\n",
    "def arlin_param(x, filters):\n",
    "    l = Flatten()(x)\n",
    "    for _ in range(2):\n",
    "        l = Dense(filters)(l)\n",
    "        l = LeakyReLU(alpha=0.2)(l)\n",
    "    return Dense(filters)(l), Dense(filters)(l)\n",
    "gamma, beta = arlin_param(g, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    g = resnet_adalin(g, gamma, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'ada_lin_simple_8/gamma:0' shape=(12,) dtype=float32> gamma\n",
      "tracking <tf.Variable 'ada_lin_simple_8/gamma:0' shape=(12,) dtype=float32> beta\n"
     ]
    }
   ],
   "source": [
    "g = deconv2d(g, depth, f_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ada_lin_simple_8/add_3:0' shape=(None, 128, 128, 12) dtype=float32>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ada_lin_9/add_3:0' shape=(None, 32, 32, 12) dtype=float32>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = Conv2D(filters, kernel_size=3, strides=1, padding='same')(l)\n",
    "l = AdaLIN()([l, gamma, beta])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3/add:0' shape=(None, 32, 32, 12) dtype=float32>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Add()([l, g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [3,3,3,5] vs. [5,1] [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-d03460cd5210>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6119\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6120\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6121\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6122\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6123\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [3,3,3,5] vs. [5,1] [Op:Mul]"
     ]
    }
   ],
   "source": [
    "tf.multiply(x,a)[...,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
