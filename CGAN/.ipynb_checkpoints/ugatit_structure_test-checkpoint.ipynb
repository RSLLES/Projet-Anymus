{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer, Input, Dense, Reshape, Flatten, Dropout, Concatenate, Add\n",
    "from keras.layers import Activation\n",
    "import keras.backend as K\n",
    "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization as InstanceNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 3\n",
    "dim = 128\n",
    "input_shape = (dim,dim,channel)\n",
    "n_resnet = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(layer_input, filters, f_size=4, strides=2, normalization=True):\n",
    "    \"\"\"Layer de base pour downsampl√©\"\"\"\n",
    "    l = Conv2D(filters, kernel_size=f_size, strides=strides, padding='same')(layer_input)\n",
    "    if normalization:\n",
    "        l = InstanceNormalization()(l)\n",
    "    l = LeakyReLU(alpha=0.2)(l)\n",
    "    return l\n",
    "\n",
    "def resnet(layer_input, filters, f_size=3):\n",
    "    l = Conv2D(filters, kernel_size=f_size, strides=1, padding='same')(layer_input)\n",
    "    l = InstanceNormalization()(l)\n",
    "    l = LeakyReLU(alpha=0.2)(l)\n",
    "    l = Conv2D(filters, kernel_size=f_size, strides=1, padding='same')(l)\n",
    "    l = InstanceNormalization()(l)\n",
    "    return Add()([l, layer_input])\n",
    "\n",
    "def resnet_adalin(layer_input, gamma, beta, f_size=3):\n",
    "    filters = layer_input.shape[-1]\n",
    "    l = Conv2D(filters, kernel_size=f_size, strides=1, padding='same')(layer_input)\n",
    "    l = AdaLIN()([l, gamma, beta])\n",
    "    l = LeakyReLU(alpha=0.2)(l)\n",
    "    l = Conv2D(filters, kernel_size=f_size, strides=1, padding='same')(l)\n",
    "    l = AdaLIN()([l, gamma, beta])\n",
    "    return Add()([l, layer_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=input_shape)\n",
    "input_layer.shape\n",
    "depth = channel\n",
    "g = conv2d(input_layer, depth, f_size=7, strides=1)\n",
    "for _ in range(2):\n",
    "    depth*=2\n",
    "    g = conv2d(g, depth, f_size=3, strides=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'leaky_re_lu_21/LeakyRelu:0' shape=(None, 32, 32, 12) dtype=float32>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaLIN(Layer):\n",
    "    def __init__(self, smoothing=True, eps = 1e-5):\n",
    "        super(AdaLIN, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.eps = eps\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if (len(input_shape) != 3):\n",
    "            raise ValueError(\"Il faut donner dans l'ordre le layer, gamma et beta\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, gamma, beta = inputs[0], inputs[1], inputs[2]\n",
    "        ch = x.shape[-1]\n",
    "        ins_mean, ins_sigma = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        x_ins = (x - ins_mean) / (tf.sqrt(ins_sigma + self.eps))\n",
    "        ln_mean, ln_sigma = tf.nn.moments(x, axes=[1, 2, 3], keepdims=True)\n",
    "        x_ln = (x - ln_mean) / (tf.sqrt(ln_sigma + self.eps))\n",
    "        rho = tf.Variable(np.ones(ch), dtype = np.float32, name=\"rho\", shape=[ch], constraint=lambda x: tf.clip_by_value(x, clip_value_min=0.0, clip_value_max=1.0))\n",
    "        if self.smoothing :\n",
    "            rho = tf.clip_by_value(rho - tf.constant(0.1), 0.0, 1.0)\n",
    "        x_hat = rho * x_ins + (1 - rho) * x_ln\n",
    "        x_hat = x_hat * gamma + beta\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaLIN_simple(Layer):\n",
    "    def __init__(self, smoothing=True, eps = 1e-5):\n",
    "        super(AdaLIN_simple, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.eps = eps\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        gamma = tf.Variable(np.ones(ch), dtype = np.float32, name=\"gamma\", shape=[ch])\n",
    "        beta = tf.Variable(np.zeros(ch), dtype = np.float32, name=\"gamma\", shape=[ch])\n",
    "        ch = x.shape[-1]\n",
    "        ins_mean, ins_sigma = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        x_ins = (x - ins_mean) / (tf.sqrt(ins_sigma + self.eps))\n",
    "        ln_mean, ln_sigma = tf.nn.moments(x, axes=[1, 2, 3], keepdims=True)\n",
    "        x_ln = (x - ln_mean) / (tf.sqrt(ln_sigma + self.eps))\n",
    "        rho = tf.Variable(np.zeros(ch), dtype = np.float32, name=\"rho\", shape=[ch], constraint=lambda x: tf.clip_by_value(x, clip_value_min=0.0, clip_value_max=1.0))\n",
    "        if self.smoothing :\n",
    "            rho = tf.clip_by_value(rho - tf.constant(0.1), 0.0, 1.0)\n",
    "        x_hat = rho * x_ins + (1 - rho) * x_ln\n",
    "        x_hat = x_hat * gamma + beta\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul(x,dense):\n",
    "    w = dense.weights\n",
    "    w = tf.gather(tf.transpose(tf.nn.bias_add(w[0], w[1])), 0)\n",
    "    return tf.multiply(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class activation map\n",
    "gmv, gav = GlobalMaxPooling2D()(g), GlobalAveragePooling2D()(g)\n",
    "dense_m, dense_a = Dense(1), Dense(1)\n",
    "cam_m, cam_a = dense_m(gmv), dense_a(gav)\n",
    "g_m, g_a = mul(g, dense_m), mul(g, dense_a)\n",
    "cam, g = Concatenate()([cam_m, cam_a]), Concatenate()([g_m, g_a])\n",
    "g = conv2d(g, depth, f_size=1, strides=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'leaky_re_lu_22/LeakyRelu:0' shape=(None, 32, 32, 12) dtype=float32>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes pour la ARLIN function\n",
    "def arlin_param(x, filters):\n",
    "    l = Flatten()(x)\n",
    "    for _ in range(2):\n",
    "        l = Dense(filters)(l)\n",
    "        l = LeakyReLU(alpha=0.2)(l)\n",
    "    return Dense(filters)(l), Dense(filters)(l)\n",
    "gamma, beta = arlin_param(g, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    g = resnet_adalin(g, gamma, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_8/add:0' shape=(None, 32, 32, 12) dtype=float32>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'leaky_re_lu_27/LeakyRelu:0' shape=(None, 32, 32, 12) dtype=float32>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = LeakyReLU(alpha=0.2)(l)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ada_lin_9/add_3:0' shape=(None, 32, 32, 12) dtype=float32>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = Conv2D(filters, kernel_size=3, strides=1, padding='same')(l)\n",
    "l = AdaLIN()([l, gamma, beta])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3/add:0' shape=(None, 32, 32, 12) dtype=float32>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Add()([l, g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [3,3,3,5] vs. [5,1] [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-d03460cd5210>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6119\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6120\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6121\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6122\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6123\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [3,3,3,5] vs. [5,1] [Op:Mul]"
     ]
    }
   ],
   "source": [
    "tf.multiply(x,a)[...,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
